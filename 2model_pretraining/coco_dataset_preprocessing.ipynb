{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025b437f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy_exported\n"
     ]
    }
   ],
   "source": [
    "### this is for running in local ###\n",
    "import os\n",
    "try:\n",
    "    os.environ['HTTP_PROXY']='http://185.46.212.90:80'\n",
    "    os.environ['HTTPS_PROXY']='http://185.46.212.90:80'\n",
    "    print (\"proxy_exported\")\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e67cca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-28 04:16:28--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.162.33, 52.217.200.137, 3.5.28.192, ...\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.162.33|:80... failed: Connection timed out.\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.200.137|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 252907541 (241M) [application/zip]\n",
      "Saving to: ‘annotations_trainval2017.zip’\n",
      "\n",
      "annotations_trainva 100%[===================>] 241.19M  2.02MB/s    in 2m 8s   \n",
      "\n",
      "2024-02-28 04:20:46 (1.89 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c03cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-25ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff9ddcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  annotations_trainval2017.zip\n",
      "  inflating: annotations/instances_train2017.json  \n",
      "  inflating: annotations/instances_val2017.json  \n",
      "  inflating: annotations/captions_train2017.json  \n",
      "  inflating: annotations/captions_val2017.json  \n",
      "  inflating: annotations/person_keypoints_train2017.json  \n",
      "  inflating: annotations/person_keypoints_val2017.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d82458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d7bea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('annotations/captions_train2017.json')\n",
    "coco_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b554e2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591753"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_dataset['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e649cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 processed\n",
      "10000 processed\n",
      "20000 processed\n",
      "30000 processed\n",
      "40000 processed\n",
      "50000 processed\n",
      "60000 processed\n",
      "70000 processed\n",
      "80000 processed\n",
      "90000 processed\n",
      "100000 processed\n",
      "110000 processed\n",
      "120000 processed\n",
      "130000 processed\n",
      "140000 processed\n",
      "150000 processed\n",
      "160000 processed\n",
      "170000 processed\n",
      "180000 processed\n",
      "190000 processed\n",
      "200000 processed\n",
      "210000 processed\n",
      "220000 processed\n",
      "230000 processed\n",
      "240000 processed\n",
      "250000 processed\n",
      "260000 processed\n",
      "270000 processed\n",
      "280000 processed\n",
      "290000 processed\n",
      "300000 processed\n",
      "310000 processed\n",
      "320000 processed\n",
      "330000 processed\n",
      "340000 processed\n",
      "350000 processed\n",
      "360000 processed\n",
      "370000 processed\n",
      "380000 processed\n",
      "390000 processed\n",
      "400000 processed\n",
      "410000 processed\n",
      "420000 processed\n",
      "430000 processed\n",
      "440000 processed\n",
      "450000 processed\n",
      "460000 processed\n",
      "470000 processed\n",
      "480000 processed\n",
      "490000 processed\n",
      "500000 processed\n",
      "510000 processed\n",
      "520000 processed\n",
      "530000 processed\n",
      "540000 processed\n",
      "550000 processed\n",
      "560000 processed\n",
      "570000 processed\n",
      "580000 processed\n",
      "590000 processed\n"
     ]
    }
   ],
   "source": [
    "# flatten the coco dataset\n",
    "coco_data_list = []\n",
    "r = 0\n",
    "for a_idx, a in enumerate(coco_dataset['annotations']):\n",
    "    image_id = a['image_id']\n",
    "    caption  = a['caption']\n",
    "    for i in coco_dataset['images']:\n",
    "        if i['id'] == image_id:\n",
    "            image_url = i['coco_url']\n",
    "            file_name = i['file_name']\n",
    "    if a_idx % 10000 == 0:\n",
    "        print(f\"{10000 * r} processed\")\n",
    "        r += 1\n",
    "  \n",
    "    coco_data_list.append([image_id,file_name,image_url,caption])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bc23bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pickle file\n",
    "with open(\"coco_dataset_pickle\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(coco_data_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aaa4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
